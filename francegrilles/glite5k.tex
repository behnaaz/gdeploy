\documentclass[a4paper,11pt]{article}
\usepackage{a4wide}
\usepackage[french]{babel}
\usepackage[utf8]{inputenc}  %or: \usepackage[latin1]{inputenc}
\usepackage{color}
\usepackage{hyperref}
\usepackage{times}

\newcommand{\todo}[1]{{\color{red}\textsl #1}}


\title{gLite sur Grid'5000:\\ vers une plate-forme d'expérimentation\\ à taille réelle pour les grilles de production}
\date{}
\author{Sébastien Badia et Lucas Nussbaum\\
\texttt{\normalsize \{sebastien.badia,lucas.nussbaum\}@loria.fr}\\[1em]
\normalsize ALGORILLE team, LORIA\\
INRIA Nancy - Grand Est \& Nancy-Université}

\begin{document}
\maketitle

\section{Overview}
\todo{Résumé en anglais}

The Grid has become a huge and important project, playing a key role in the
everyday work of many researchers. A large amount of software is being developed
both to manage the grid infrastructure itself (gLite middleware\cite{glite}),
to facilitate the task of grid users (e.g workflow managers\cite{moteur},
pilot job managers, etc.), and to run the computations themselves.
That software must be designed to handle network and services outages in a
highly distributed environment, while still providing the expected performance.
It is inconvenient to test software using the production infrastructure, since
(1) it might not exhibit the behaviour that is required to test extreme
conditions (services are unlikely to crash as often as required when testing
fault tolerance); (2) it might not be possible to replace key parts of the
infrastructure without degrading the user experience.

In this paper, we present our ongoing work on deploying the gLite middleware on
the Grid'5000 testbed. Grid'5000 is a scientific instrument designed to support
research on parallel, large-scale and distributed computing. It is composed of
FIXME nodes (FIXME cores) with unique hardware and network reconfiguration
features: users can reserve nodes, and then automatically re-install them with
the software environment required for their experiments.

% FIXME réécrire sous forme d'un (vrai) résumé

\section{Enjeux scientifiques}
\todo{Enjeux scientifiques, besoin de la grille : Environ une demi-page}

La devenue est devenue une immense et importante plate-forme, qui joue un rôle
clé dans la travail quotidien de nombreux chercheurs. Un grand nombre de
logiciels ont été développés pour gérer l'infrastructure elle-même (middleware
gLite\cite{glite}), pour faciliter le travail des utilisateurs (moteurs de
workflows comme MOTEUR~\cite{moteur}, gestionnaires de jobs pilotes, etc.), et
pour exécuter les traitements eux-mêmes.
Ces logiciels doivent être conçus pour prendre en compte les pannes à
différents niveaux (réseaux, services), dans une infrastructure largement
distribuée, tout en fournissant les performances requises.

Il est en général difficile de tester ces logiciels en utilisant
l'infrastructure de production. D'une part, il est peu probable que
l'infrastructure de production fournisse le comportement souhaité pendant les
tests : lors du test de la résistance aux pannes d'un logiciel, il serait peu
confortable d'attendre une panne sur l'infrastructure de production pour
vérifier son bon fonctionnement. D'autre part, il n'est pas forcément possible
de remplacer un composant central de l'infrastructure pour en tester une
modification sans gêner les utilisateurs.

Dans ce travail, nous proposons d'utiliser la plate-forme
Grid'5000~\cite{grid5000,grid5000web}, dédiée à la recherche sur les systèmes
et le calcul parallèle, pour tester l'infrastructure logicielle des grilles de
production.

\section{Développements et outils}
\todo{Développements, déploiement sur la grille : Environ une demi-page}
\todo{Outils, difficultés rencontrées : Environ une demi-page}

La plate-forme Grid'5000 est composée de 1700 machines (7000 coeurs) répartis
dans 10 sites en France. Elle dispose de fonctionnalités de reconfiguration du
matériel et du réseau : les utilisateurs peuvent, après avoir réservé des
ressources, réinstaller les machines réservées avec le système requis pour leur
expérience.

Cette fonctionnalité a été utilisée pour développer un ensemble de scripts
permettant d'automatiser le déployement d'une infrastructure gLite sur
Grid'5000, composée de:

\begin{itemize}

\item une VO et son VOMS (\textsl{Virtual Organization Membership Service}),
	annuaire des utilisateurs ;

\item plusieurs sites, composés de:

\begin{itemize}

	\item un BDII (\textsl{Berkeley Database Information Index}), annuaire
		des ressources disponibles sur chaque site ;

	\item un CE (\textsl{Computing Element}), interface de soumission des
		tâches ;

	\item un WMS (\textsl{Workload Management System}); dans le cadre de
		notre travail, le couple Torque/Maui a été utilisé ;

	\item une UI (\textsl{User Interface}), interface d'accès pour les
		utilisateurs ;

	\item un ou plusieurs clusters composés de noeuds de calcul.

\end{itemize}
\end{itemize}

Le processus est composé de différentes étapes implémentées dans différents
scripts qu'il est possible d'enchainer automatiquement.  D'abord, les machines
réservées sont réinstallées avec une installation Scientific Linux 5.5
minimale. Puis le dépôt RPM de gLite (\textsl{glitesoft.cern.ch}) est ajouté,
et les paquets nécessaires sont installés en fonction du rôle choisi pour la
machine cible (VOMS, BDII, noeud de travail, \ldots). Enfin, l'ensemble des
noeuds sont configurés.

\todo{dire un mot de l'infra au niveau certificats ?}
gLite repose sur un système de certificats clients/serveurs, pour autoriser l'accès
ou non aux ressources, trois possibilités :
\begin{listing}
\item Demander un certificat signé par une autorité de certification externe
\item Créer sa	propre autorité et signer soit même les certificats (SimpleCA).
\item Créer un certificat auto-signé et l'injecter dans la racine
\end{listing}
Nous avons donc suivi la méthode 2, une autorité de certification est donc déployé à
l'aide des scipts "simpleCA" disponible dans l'archive Globus.\footnote{http://www.globus.org/toolkit/docs/4.0/admin/docbook/ch07.html}
Celle-ci est situé sur note voms, des scripts ont été développés pour permettre la signature
immédiate et transparent des certificats machine et utilisateurs.

Deux difficultés importantes ont été rencontrées :

\begin{itemize}

\item S'il existe une documentation abondante sur la configuration de gLite,
	les différents documents sont de qualité inégale, parfois dépassés ou
	incomplets. Il est dommage qu'il n'y ait pas  plus d'effort de
	centralisation de la documentation, ce qui améliorerait sa qualité.

\item Le processus d'installation de gLite est prévu pour être réalisé à la
	main. L'automatiser, et en particulier automatiser la gestion des
	certificats, a été loin d'être évident.

\end{itemize}

Les scripts utilisés sont disponibles et documentés sur \url{https://github.com/sbadia/gdeploy/}.

\todo{nettoyer le dépot git: merger multi dans master, supprimer les fichiers utiles, rajouter un README.}

\section{Résultats scientifiques}
\todo{Résultats scientifiques : Environ une demi-page à trois quarts de page}

Avec les scripts développés, nous avons réalisé le déploiement de gLite sur XX
machines de Grid'5000, réparties dans XX sites et XX clusters (figure
\ref{depl}). Le déploiement de l'environnement Scientific Linux sur l'ensemble
des machines avec Kadeploy a pris XX minutes, et la configuration de l'ensemble
des noeuds gLite a pris XX minutes.

\section{Perspectives}
\todo{Perspectives : Environ une demi-page}

Ce travail vise à démontrer la faisabilité de l'utilisation de Grid'5000 pour
tester ou évaluer des logiciels de l'écosystème des grilles de production.

Nos scripts peuvent être assez largement améliorés. Une première étape est de
permettre de configurer une plate-forme composée d'un nombre de VOs, de sites
et de clusters arbitraires (sans rapport avec l'architecture des ressources
réservées sur Grid'5000) afin de pouvoir se placer dans des configurations
expérimentales plus variées et intéressantes.

Concernant la durée de déploiement, la configuration de l'ensemble des machines
se fait de manière séquentielle, ce qui explique la durée très importante du
déploiement. Nous explorons actuellement l'utilisation d'un moteur de workflow
pour orchestrer les différentes étapes du déploiement, ce qui permettra
d'extraire le parallélisme implicite entre les différentes étapes et devrait
significativement réduire la durée du déploiement. D'autres améliorations sont
également prévues, comme l'ajout d'un cache pour les paquets RPM de Scientific
Linux ce qui réduira la charge sur les serveurs \textsl{proxy} HTTP de
Grid'5000, et la modification de l'image Scientific Linux afin qu'elle puisse
fonctionner sur l'ensemble des clusters de Grid'5000.

De plus, l'infrastructure actuellement déployée est relativement simple. Nous
ne déployons pour l'instant pas de services de gestion de stockage ni de
services annexes (Monitor, par exemple). La gestion des VO et des utilisateurs
est également assez simpliste.

Ce travail n'est pas une fin en soi. Nous cherchons des utilisateurs ou
développeurs de logiciels pour la grille ayant des besoins en expérimentation
de leurs logiciels. En particulier, nous envisageons les cas d'utilisation
suivants :

\begin{itemize}

\item \textit{Expériences sur des évolutions de composants du middleware
	gLite}, qui pourront ainsi être réalisées à grande échelle sans
	affecter les utilisateurs de la grille ;

\item \textit{Expériences sur des outils interagissant avec le middleware
	gLite}, éventuellement en simulant la panne de services, en injectant
	de la charge applicative, etc.

\end{itemize}

\section{Références}
\todo{Références : Environ une demi-page}



\section*{Remerciements}

Ce travail a été en partie financé par le thème EDGE du CPER MISN de la Région
Lorraine et par l'appel \textsl{Interfaces Recherche en grilles - Grilles de
production} de l'Institut des Grilles du CNRS et de l'action INRIA Aladdin-G5K.

\end{document}

